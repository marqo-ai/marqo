{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marqo\n",
    "import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "### STEP 1: Load Data\n",
    "####################################################\n",
    "def load_data(file: str, number_data: int) -> dict:\n",
    "    podcast_data = pd.read_csv(file).head(number_data)[['name', 'description']].to_dict('records')\n",
    "\n",
    "    # dataset came from this link: https://www.vox.com/today-explained\n",
    "    # the .csv file has the following headers:\n",
    "    # name, description\n",
    "    # (name of podcast, short description)\n",
    "\n",
    "    # create a 'transcript' key and add the transcript text as values to each record\n",
    "    id_counter = 1\n",
    "    for data in podcast_data:\n",
    "        path = \"data/transcripts/\" + data['name'] + \".txt\"\n",
    "        with open(path, 'r') as f:\n",
    "            content = f.read()\n",
    "            data['transcript'] = content\n",
    "            data['_id'] = str(id_counter)  # _id is a special key which is unique to every document\n",
    "        id_counter += 1\n",
    "\n",
    "    return podcast_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nformat of podcast_data -\\n[{'name': '....', 'description': '....', 'transcript': '....'}, \\n{'name': '....', 'description': '....', 'transcript': '....'}]\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_file = \"data/podcast_data.csv\"\n",
    "podcast_data = load_data(dataset_file, 2)\n",
    "'''\n",
    "format of podcast_data -\n",
    "[{'name': '....', 'description': '....', 'transcript': '....'}, \n",
    "{'name': '....', 'description': '....', 'transcript': '....'}]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "### STEP 2. Start Marqo\n",
    "#####################################################\n",
    "\n",
    "# Follow the instructions here https://github.com/marqo-ai/marqo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "### STEP 3: Index Data\n",
    "####################################################\n",
    "index_name = \"marqo-podcast-search-demo\"\n",
    "mq = marqo.Client(url='http://localhost:8882')  # Connection to Marqo Docker Container\n",
    "mq.index(index_name).add_documents(podcast_data)  # If the index doesn't exist, Marqo will create it\n",
    "stats = mq.index(index_name).get_stats()  # get the stats for the index\n",
    "print(f\"{stats['numberOfDocuments']} documents added to index: {index_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "### STEP 4: Search using Marqo\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a query and perform tensor search\n",
    "query = 'what is long covid?'\n",
    "results = mq.index(index_name).search(query)\n",
    "\n",
    "# ['_highlights'] will return only the relevant portion rather than the whole transcript\n",
    "print(\"Result 1 -\", end=\" \")\n",
    "pprint.pprint(results['hits'][0]['_highlights'])  # [0] returns the top hit\n",
    "print(\"Result 2 -\", end=\" \")\n",
    "pprint.pprint(results['hits'][1]['_highlights'])  # [1] returns the second hit\n",
    "\n",
    "\n",
    "# let's create another query and perform tensor search on a particular field\n",
    "query = 'water issues in US'\n",
    "results = mq.index(index_name).search(query, searchable_attributes=['description'])\n",
    "\n",
    "print(\"Result 3 -\", end=\" \")\n",
    "pprint.pprint(results['hits'][0]['_highlights'])\n",
    "\n",
    "\n",
    "# let's create another query and perform lexical search on a particular field\n",
    "query = 'water crisis'\n",
    "results = mq.index(index_name).search(query, searchable_attributes=['name'], search_method='LEXICAL')\n",
    "\n",
    "print(\"Result 4 -\", end=\" \")\n",
    "pprint.pprint(results['hits'][0]['name'])\n",
    "print(\"Result 5 -\", end=\" \")\n",
    "pprint.pprint(results['hits'][0]['_highlights'])  # [_highlights] will return an empty list if using lexical search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ccb58c476f33ba3e3aee7ac07234ef6b8217ef24ad64d2a7d4fed1a57c1cd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
